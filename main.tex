\documentclass[conference]{IEEEtran}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage[hyphens]{url}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

% Ensure letter paper
\pdfpagewidth=8.5in
\pdfpageheight=11in

%%%%%%%%%%%---SETME-----%%%%%%%%%%%%%
\newcommand{\iscasubmissionnumber}{NaN}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\pagenumbering{arabic}

%%%%%%%%%%%---SETME-----%%%%%%%%%%%%%
\title{A Survey of Graphical Processing Units}
\author{\normalsize{Inji Kim and Kavish Ranawella and Andrew Davis}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\maketitle
\thispagestyle{plain}
\pagestyle{plain}



%%%%%% -- PAPER CONTENT STARTS-- %%%%%%%%

\begin{abstract}
  This paper is a survey on Graphical Processing Units (GPUs).
  The sections were divided the following way: The introduction and conclusion were collaborative.
  Inji Kim wrote the section on Architecture, Kavish Ranawella wrote the section on Simulators, and Andrew Davis wrote the section on Memory Models.
\end{abstract}

\section{Introduction}
GPUs are powerful accelerators that are becoming widely used in all aspects of computing, such as machine learning, computational fluid dynamics, image processing, and other general purpose computing on graphics processing units (GPGPU) tasks.
The underlying architecture, memory models, and simulator tools are both similar and distinct from a traditional central processing unit (CPU).
In this survey of GPUs, we will discuss the underlying architecture, memory models, and the current state of the art GPU simulators.
We will also discuss some of the state of the art improvements to the underlying architecture, memory models, and GPU simulators.

The Architecture section explores GPU structure and optimization techniques, focusing on key components such as the Shader Core and hierarchical memory. It examines performance bottlenecks like memory access issues, resource imbalance, and branch divergence, and discusses solutions including scheduling optimizations and Thread Block Compaction (TBC).
It also highlights tools for enhancing GPU performance, such as GASS (an open-source GPU compiler), a GPU ISA decoding platform, Xscope (a floating-point exception detection framework), and neural network acceleration methods like VectorSparse and Tensor Core.

The memory models section is organized as follows: an overview of the hierarchy of GPU on chip memory, i.e. caches, shared memory, etc, is discussed, followed by a brief overview of off chip memory, i.e. DRAM.
Some of the state of the art implementations of GPU memory models to be discussed are: memory-coalescing strategies, private vs shared cache design, synchronization strategies, cache coherence, specific findings of underlying memory hardware, virtual memory, and virtual memory addressing schemes.

The simulators section will discuss the importance of investing considerable research effort into developing open-source simulators, examine the current state-of-the-art simulators and highlight the benefits they have provided so far.
The focus will be on how these simulators need to be updated to model the modern GPUs, with most examples drawn from NVIDIA's ecosystem.
The overall flow will illustrate how these simulators have been progressively extended, increasing their generalizability and applicability over time.

\include{architecture}
\include{memory}
\include{simulators}
\section{Conclusion}
We have written an overview of the key components of the GPU, those being, the underlying architecture, the memory models, and the simulators used to test new GPU architecture ideas.
We have also relayed some of the state of the art findings from various academic papers on these concepts.
The following three paragraphs are a brief summary of the concepts detailed in Sections II to IV. The content is organized in the following way: architecture, memory models, and simulators.

The architecture of GPUs plays a crucial role in fields such as scientific research, artificial intelligence, and simulations. To overcome performance limitations and expand their range of applications, technologies like scheduling optimizations and Thread Block Compaction (TBC) have been introduced to address challenges such as memory bottlenecks, resource imbalance, and branch divergence.
The development of GPUs has significantly improved parallel computing efficiency. Open-source platforms like GASS enhance collaboration between hardware and software, while GPU ISA decoding platforms bridge gaps in closed architectures. Tools like Xscope and VectorSparse further optimize GPU efficiency and open new possibilities for applications.
NVIDIA GPUs have continuously evolved through ongoing hardware and software improvements. These advancements, supported by various tools and technologies, have further expanded the scope of GPU applications.

Inter-warp memory coalescing was found to be highly efficient by Bakhoda.
Ibrahim found performance gains when shifting from a private L1 cache to a shared L1 cache.
Fung describes a transactional memory policy that is superior to traditional lock-based synchronizations.
Singh explored a method that enabled cache coherence on the GPU, and found their method improved performance of some applications.
Mei and Chu deliver precise experimental findings of the Fermi, Kepler, and Maxwell GPU architectures that were not disclosed by NVIDIA; these findings are primarily on cache behavior, such as eviction policies and cache line size.
Pratheek found a virtual memory system design that improves memory performance for GPUs that use MCM technologies.
Lastly, Liu explored memory addressing modes that perform well on GPUs, these modes are application dependent and take into account an addresses bit entropy region.

Significant innovations in GPU technology comes from the industry, but many of the advancements are not disclosed to the public.
In order for research efforts to remain impactful, modern GPUs need to be accurately modeled through open-source simulators.
GPGPU-Sim laid the foundation for most modern GPU simulators, and these simulators use baseline assumptions to fill the knowledge gaps left by the industry.
However, incorrect baseline assumptions can misdirect research efforts and lead to incorrect conclusions.
With the increasing complexity of modern GPUs, it has become critical to simulate both detailed cycle-level performance and power models.
Developing generalized frameworks is essential to keep pace with the rapid evolution GPU hardware.
Tools like Accel-Sim and Accel-Wattch made significant advancements in this area, serving as game changers in accurately modeling modern GPUs.
These simulators have proven that oversimplified baseline assumptions can lead to misleading insights, emphasizing the need for more accurate and detailed modeling approaches.

\clearpage
\appendix
\section{Notes}
Notes that won't be included in the final draft:
\subsection{Topics}
List of project topics and the papers that correspond to those topics
\subsubsection{Memory Models}
\cite{Bakhoda2009}
\cite{Ibrahim2020}
\cite{Singh2013}
\cite{Pratheek2023}
\cite{Mei2015}
\cite{Liu2018}
\cite{Fung2011ISM}
\cite{Jog2013OWL}
\cite{Kadam2018}
\cite{Liu2020}
\cite{Jog2013}
\subsubsection{Architecture}
\cite{Bakhoda2009}
\cite{Yan2022}
\cite{Hayes2019}
\cite{Sanudo2020}
\cite{Laguna2022}
\cite{Zhu2019}
\cite{Fung2011HPC}
\subsubsection{GPU simulators}
\cite{Khairy2020}
\cite{Kandiah2021}
\cite{Bakhoda2009}
\cite{Hayes2019}
\cite{Raihan2018}
\cite{Liu2020}
\cite{Jog2013}


%%%%%%%%% -- BIB STYLE AND FILE -- %%%%%%%%
\bibliographystyle{IEEEtranS}
\bibliography{refs}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}

